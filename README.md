# ğŸ® Asistente IA de Videojuegos ğŸ¤–

Â¡Bienvenido! Este proyecto es una aplicaciÃ³n web full-stack que funciona como un asistente inteligente y especializado en el universo de los videojuegos. Utiliza el poder del modelo de lenguaje grande (LLM) de Google, **Gemini**, para ofrecer respuestas expertas en tres Ã¡reas: recomendaciones, anÃ¡lisis de notas/reseÃ±as y guÃ­as/trucos.

El proyecto estÃ¡ completamente **dockerizado** para un despliegue fÃ¡cil y consistente, y se conecta a una base de datos **PostgreSQL** en la nube para registrar el historial de conversaciones.

---
## ğŸ›ï¸ Arquitectura

La aplicaciÃ³n sigue una arquitectura desacoplada, asegurando que cada componente sea independiente y fÃ¡cil de mantener.

* **ğŸ–¥ï¸ Frontend**: Una interfaz de usuario limpia construida con **HTML, CSS y JavaScript**.
* **âš™ï¸ Backend (API)**: Una API RESTful robusta creada con **Flask (Python)** que actÃºa como el cerebro, orquestando las peticiones del usuario, la lÃ³gica de la IA y la persistencia de datos.
* **ğŸ§  LÃ³gica del LLM**: Un mÃ³dulo especializado en Python que se encarga de construir prompts inteligentes y comunicarse directamente con la **API de Gemini**.
* **ğŸ’¾ Base de Datos**: Un mÃ³dulo de persistencia que maneja todas las transacciones con una base de datos **PostgreSQL** externa.

---
## âœ¨ TecnologÃ­as Utilizadas

Una selecciÃ³n de tecnologÃ­as modernas para construir una aplicaciÃ³n robusta y escalable.

| CategorÃ­a         | TecnologÃ­a                                                                                             |
| :---------------- | :----------------------------------------------------------------------------------------------------- |
| **Backend** | ğŸ Python, Flask                                                                                       |
| **Base de Datos** | ğŸ˜ PostgreSQL                                                                                         |
| **IA & LLM** | ğŸ§  Google Gemini API                                                                                   |
| **Frontend** | ğŸŒ HTML, CSS, JavaScript (Vanilla)                                                                     |
| **Testing** | âœ… Pytest                                                                                              |
| **ContenerizaciÃ³n**| ğŸ³ Docker                                                                                              |
| **Despliegue** | â˜ï¸ Render / AWS                                                                                        |
| **LibrerÃ­as Clave**| `psycopg2-binary`, `requests`, `python-dotenv`                                                         |

---
## ğŸ› ï¸ ConfiguraciÃ³n del Entorno Local

Sigue estos pasos para poner en marcha el proyecto en tu mÃ¡quina.

### 1ï¸âƒ£ Clonar el Repositorio
```bash
git clone https://github.com/EduardoLimones/LLM_APP.git
cd LLM_APP
```

### 2ï¸âƒ£ Crear y Activar Entorno Virtual
```bash
# Crear el entorno
python -m venv venv

# Activar en Windows
venv\Scripts\activate

# Activar en macOS/Linux
source venv/bin/activate
```

### 3ï¸âƒ£ Instalar Dependencias
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configurar Variables de Entorno
Crea un archivo llamado `.env` en la raÃ­z del proyecto. Este archivo es secreto y no debe subirse a Git. Copia el siguiente contenido y rellÃ©nalo con tus credenciales.

```env
# ğŸ¤« Archivo .env - Variables de Entorno

# === Secretos de la Base de Datos PostgreSQL ===
DB_HOST=TU_HOST_DE_AWS_AQUÃ
DB_USER=TU_USUARIO_DE_LA_BBDD_AQUÃ
DB_PASSWORD=TU_CONTRASEÃ‘A_DE_LA_BBDD_AQUÃ
DB_PORT=5432
DB_NAME=EL_NOMBRE_DE_TU_BBDD_AQUÃ

# === Secreto de la API de Gemini ===
API_KEY=TU_API_KEY_DE_GEMINI_AQUÃ
```

---
## ğŸš€ CÃ³mo Ejecutar la AplicaciÃ³n

Una vez configurado el entorno, inicia el servidor de Flask.
```bash
python app.py
```
La aplicaciÃ³n estarÃ¡ disponible en `http://127.0.0.1:5000`.

*Nota: La primera vez que se ejecute, se intentarÃ¡ crear la tabla `preguntas_respuestas` en la base de datos si no existe.*

---
## ğŸ”Œ Uso de la API

La API expone tres endpoints principales que aceptan peticiones `POST` con un cuerpo JSON.

* `/recomendacion`
* `/resena`
* `/guia`

#### Ejemplo de PeticiÃ³n con `curl`
```bash
curl -X POST \
  -H "Content-Type: application/json" \
  -d '{"pregunta": "RecomiÃ©ndame un buen RPG para PC"}' \
  [http://127.0.0.1:5000/recomendacion](http://127.0.0.1:5000/recomendacion)
```

---
## âœ… CÃ³mo Ejecutar los Tests

Para verificar que la API funciona correctamente:

1.  En una terminal, asegÃºrate de que la aplicaciÃ³n principal se estÃ¡ ejecutando: `python app.py`.
2.  En una **segunda terminal**, ejecuta `pytest`:
    ```bash
    pytest
    ```

---
## ğŸ³ Despliegue con Docker

Este proyecto estÃ¡ preparado para ser desplegado con Docker para una mÃ¡xima portabilidad.

### 1. Construir la Imagen
```bash
docker build -t eduardolimones/mi-asistente-ia:1.0 .
```

### 2. Ejecutar el Contenedor
AsegÃºrate de pasar las variables de entorno a travÃ©s del archivo `.env`.
```bash
docker run -d -p 5000:5000 --env-file ./.env --name mi-contenedor eduardolimones/mi-asistente-ia:1.0
```
La aplicaciÃ³n estarÃ¡ disponible en `http://localhost:5000`.

---
## ğŸ‘¨â€ğŸ’» Autor

Desarrollado por **Eduardo JosÃ© Limones Contreras**.

* **LinkedIn**: [Perfil de LinkedIn](https://www.linkedin.com/in/eduardo-jos%C3%A9-limones-contreras-b1348677/)
* **Correo**: `eduardo.limones.contreras@gmail.com`
